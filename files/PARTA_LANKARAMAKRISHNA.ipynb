{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-05T17:08:51.610251Z",
     "iopub.status.busy": "2024-11-05T17:08:51.606254Z",
     "iopub.status.idle": "2024-11-05T17:08:51.631442Z",
     "shell.execute_reply": "2024-11-05T17:08:51.629654Z",
     "shell.execute_reply.started": "2024-11-05T17:08:51.610162Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOADING THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T17:08:51.634695Z",
     "iopub.status.busy": "2024-11-05T17:08:51.634184Z",
     "iopub.status.idle": "2024-11-05T17:11:12.181053Z",
     "shell.execute_reply": "2024-11-05T17:11:12.178569Z",
     "shell.execute_reply.started": "2024-11-05T17:08:51.634649Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the HIGGS dataset\n",
    "df = pd.read_csv('/kaggle/input/higgs-uci-dataset/HIGGS.csv')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STRATIFIED SAMPLING OF THE DATA\n",
    "\n",
    "Stratified Sampling the data so that we get equal number of classes in output of the sampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T17:11:12.185191Z",
     "iopub.status.busy": "2024-11-05T17:11:12.184743Z",
     "iopub.status.idle": "2024-11-05T17:11:24.478080Z",
     "shell.execute_reply": "2024-11-05T17:11:24.476290Z",
     "shell.execute_reply.started": "2024-11-05T17:11:12.185131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Calculate the sample size (0.01% of the dataset)\n",
    "sample_size = int(0.0001 * len(df))\n",
    "\n",
    "# Assuming the target variable is the last column (0 for background, 1 for signal)\n",
    "# Change 'target_column_name' to the actual name if different\n",
    "target_column_name = '1.000000000000000000e+00'  # Replace with the actual column name if needed\n",
    "\n",
    "# Create a stratified sample\n",
    "stratified_sample, _ = train_test_split(df, train_size=sample_size, stratify=df[target_column_name], random_state=42)\n",
    "\n",
    "# Display the stratified sample\n",
    "print(stratified_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Basic Statistics\n",
    "\n",
    "We begin by displaying basic statistics for the stratified sample using the `describe()` method. This provides an overview of the dataset's features.\n",
    "\n",
    "Next, we calculate the number of rows and columns needed for subplots based on the number of features (excluding the target column). We set a fixed number of columns for the plots and compute the required rows.\n",
    "\n",
    "### Feature Distribution Plots\n",
    "\n",
    "We create histograms with Kernel Density Estimates (KDE) for each feature to visualize their distributions.\n",
    "\n",
    "### Boxplots for Outliers\n",
    "\n",
    "Boxplots are generated for each feature to identify potential outliers, providing insights into the spread and skewness of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T17:11:24.483773Z",
     "iopub.status.busy": "2024-11-05T17:11:24.483252Z",
     "iopub.status.idle": "2024-11-05T17:11:41.284268Z",
     "shell.execute_reply": "2024-11-05T17:11:41.282896Z",
     "shell.execute_reply.started": "2024-11-05T17:11:24.483725Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Display basic statistics\n",
    "print(\"Basic Statistics:\")\n",
    "print(stratified_sample.describe())\n",
    "\n",
    "# Calculate rows and columns for subplots based on number of features\n",
    "num_features = len(stratified_sample.columns) - 1  # Exclude target column\n",
    "cols = 5  # Choose number of columns\n",
    "rows = math.ceil(num_features / cols)  # Calculate rows based on number of features\n",
    "\n",
    "# Plot distributions of each feature\n",
    "plt.figure(figsize=(20, 4 * rows))\n",
    "for i, column in enumerate(stratified_sample.columns[1:], 1):  # Skip the target column\n",
    "    plt.subplot(rows, cols, i)\n",
    "    sns.histplot(stratified_sample[column], kde=True)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Boxplots for outliers\n",
    "plt.figure(figsize=(20, 4 * rows))\n",
    "for i, column in enumerate(stratified_sample.columns[1:], 1):  # Skip the target column\n",
    "    plt.subplot(rows, cols, i)\n",
    "    sns.boxplot(x=stratified_sample[column])\n",
    "    plt.title(f'Boxplot of {column}')\n",
    "    plt.xlabel(column)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NORMALISATION OF DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T17:17:01.350685Z",
     "iopub.status.busy": "2024-11-05T17:17:01.350210Z",
     "iopub.status.idle": "2024-11-05T17:17:01.380936Z",
     "shell.execute_reply": "2024-11-05T17:17:01.379860Z",
     "shell.execute_reply.started": "2024-11-05T17:17:01.350644Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the features\n",
    "X_normalized = scaler.fit_transform(stratified_sample)\n",
    "\n",
    "# Convert back to DataFrame\n",
    "X_normalized = pd.DataFrame(X_normalized, columns=stratified_sample.columns)\n",
    "\n",
    "# Display the first few rows of the normalized data\n",
    "print(X_normalized)\n",
    "y=X_normalized['1.000000000000000000e+00']\n",
    "# Drop a specific column (e.g., 'column_name') from X_normalized\n",
    "X_normalized = X_normalized.drop('1.000000000000000000e+00', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T17:17:06.176991Z",
     "iopub.status.busy": "2024-11-05T17:17:06.176565Z",
     "iopub.status.idle": "2024-11-05T17:17:06.195189Z",
     "shell.execute_reply": "2024-11-05T17:17:06.193939Z",
     "shell.execute_reply.started": "2024-11-05T17:17:06.176949Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Define the degree for polynomial features (e.g., 2 for quadratic)\n",
    "degree = 2\n",
    "\n",
    "# Initialize PolynomialFeatures with interaction_only=False to include polynomial terms\n",
    "poly = PolynomialFeatures(degree=degree, interaction_only=False, include_bias=False)\n",
    "\n",
    "# Generate polynomial and interaction features for X\n",
    "X_poly = poly.fit_transform(X_normalized)\n",
    "\n",
    "# Display the shape and a few rows of the new feature matrix\n",
    "print(\"Original feature matrix shape:\", X_normalized.shape)\n",
    "print(\"Polynomial feature matrix shape:\", X_poly.shape)\n",
    "print(\"Polynomial features (first 5 rows):\\n\", X_poly[:5])\n",
    "X_normalized= pd.DataFrame(X_poly)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RECURSIVE FEATURE ELIMINATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T17:17:08.477087Z",
     "iopub.status.busy": "2024-11-05T17:17:08.476645Z",
     "iopub.status.idle": "2024-11-05T17:17:08.792628Z",
     "shell.execute_reply": "2024-11-05T17:17:08.790993Z",
     "shell.execute_reply.started": "2024-11-05T17:17:08.477047Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "# Split into train and test sets using X1 as features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Create RFE model and select the top n features\n",
    "rfe = RFE(estimator=model, n_features_to_select=20)  # Specify the number of features you want to select\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features_rfe = X1.columns[rfe.support_].tolist()\n",
    "print(\"Selected features using RFE:\", selected_features_rfe)\n",
    "\n",
    "# Create a new DataFrame with the selected features\n",
    "X_selected = X1[selected_features_rfe]\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(\"DataFrame with selected features:\")\n",
    "print(X_selected.head())\n",
    "X=X_selected\n",
    "X.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPLITTING THE DATA FOR CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T17:17:17.101638Z",
     "iopub.status.busy": "2024-11-05T17:17:17.101081Z",
     "iopub.status.idle": "2024-11-05T17:17:17.119313Z",
     "shell.execute_reply": "2024-11-05T17:17:17.117853Z",
     "shell.execute_reply.started": "2024-11-05T17:17:17.101589Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# Select the first two features for visualization (adjust if needed)\n",
    "X_selected = X_train_scaled[:, :2]  # Select only two features for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LINEAR SVM IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T17:17:20.486742Z",
     "iopub.status.busy": "2024-11-05T17:17:20.486275Z",
     "iopub.status.idle": "2024-11-05T17:17:31.958785Z",
     "shell.execute_reply": "2024-11-05T17:17:31.956875Z",
     "shell.execute_reply.started": "2024-11-05T17:17:20.486692Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Check if we have exactly 2 features selected for visualization\n",
    "if X_selected.shape[1] == 2:\n",
    "    # Define and train the SVM model on the selected features\n",
    "    svm_model_2d = SVC(kernel='linear', probability=True)\n",
    "    svm_model_2d.fit(X_selected, y_train)\n",
    "\n",
    "    # Create a mesh grid for plotting decision boundary\n",
    "    x_min, x_max = X_selected[:, 0].min() - 1, X_selected[:, 0].max() + 1\n",
    "    y_min, y_max = X_selected[:, 1].min() - 1, X_selected[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                         np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "    # Predict on the mesh grid\n",
    "    Z = svm_model_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot the decision boundary\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.8, cmap='viridis')\n",
    "    plt.scatter(X_selected[:, 0], X_selected[:, 1], c=y_train, edgecolors='k', marker='o', cmap='viridis')\n",
    "    plt.title('SVM with Linear Kernel (Top 2 Features)')\n",
    "    plt.xlabel('Feature 1 (standardized)')\n",
    "    plt.ylabel('Feature 2 (standardized)')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"The dataset must have exactly 2 features for visualization.\")\n",
    "\n",
    "# Cross-validation on the full training set with all features\n",
    "svm_model_full = make_pipeline(StandardScaler(), SVC(kernel='linear'))\n",
    "cv_scores = cross_val_score(svm_model_full, X_train, y_train, cv=5)  # 5-fold cross-validation\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean cross-validation score:\", np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACCURACY METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T17:17:31.962756Z",
     "iopub.status.busy": "2024-11-05T17:17:31.962151Z",
     "iopub.status.idle": "2024-11-05T17:17:32.370861Z",
     "shell.execute_reply": "2024-11-05T17:17:32.369658Z",
     "shell.execute_reply.started": "2024-11-05T17:17:31.962694Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, roc_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Train the full SVM model with all features\n",
    "svm_model_full.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm_model_full.predict(X_test_scaled)\n",
    "\n",
    "# Calculate classification metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')  # Use 'weighted' for multiclass\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print classification metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# AUC score (only applicable for binary or one-vs-all multiclass)\n",
    "# If binary classification:\n",
    "y_pred_prob = svm_model_full.decision_function(X_test_scaled)\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(\"AUC Score:\", auc)\n",
    "    \n",
    "# Plot ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOCHASTIC GRADIENT DESCENT FOR SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T17:17:32.372666Z",
     "iopub.status.busy": "2024-11-05T17:17:32.372261Z",
     "iopub.status.idle": "2024-11-05T17:17:32.406291Z",
     "shell.execute_reply": "2024-11-05T17:17:32.404835Z",
     "shell.execute_reply.started": "2024-11-05T17:17:32.372625Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Create an SGDClassifier with SVM loss (Hinge Loss for SVM)\n",
    "sgd_svm = SGDClassifier(loss='hinge', max_iter=1000, tol=1e-3, random_state=42)\n",
    "\n",
    "# Train the model using mini-batches\n",
    "sgd_svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = sgd_svm.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM WITH POLYNOMIAL KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T17:18:17.140794Z",
     "iopub.status.busy": "2024-11-05T17:18:17.140336Z",
     "iopub.status.idle": "2024-11-05T17:18:55.552037Z",
     "shell.execute_reply": "2024-11-05T17:18:55.550699Z",
     "shell.execute_reply.started": "2024-11-05T17:18:17.140746Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Define the degrees to test\n",
    "degrees = [2, 3, 4]\n",
    "\n",
    "# Initialize a dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Loop over each degree and evaluate the model\n",
    "for degree in degrees:\n",
    "    print(f\"\\n--- Polynomial Kernel with Degree {degree} ---\")\n",
    "    \n",
    "    # Define and train the SVM model with a polynomial kernel\n",
    "    svm_model_poly = SVC(kernel='poly', degree=degree, probability=True)\n",
    "    svm_model_poly.fit(X_selected, y_train)  # Assuming X_selected contains only 2 features\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = svm_model_poly.predict(X_test_scaled[:, :2])  # Using the same 2 features for testing\n",
    "    y_pred_prob = svm_model_poly.decision_function(X_test_scaled[:, :2])\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # For AUC, handle binary and multiclass cases separately\n",
    "    if len(set(y)) == 2:\n",
    "        auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    else:\n",
    "        y_test_binarized = label_binarize(y_test, classes=np.unique(y))\n",
    "        auc = roc_auc_score(y_test_binarized, y_pred_prob, average=\"weighted\", multi_class=\"ovr\")\n",
    "\n",
    "    # Print results for the current degree\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "    print(f\"AUC Score: {auc:.2f}\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    # Store the results\n",
    "    results[degree] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': auc\n",
    "    }\n",
    "\n",
    "    # Plot the decision boundary\n",
    "    x_min, x_max = X_selected[:, 0].min() - 1, X_selected[:, 0].max() + 1\n",
    "    y_min, y_max = X_selected[:, 1].min() - 1, X_selected[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                         np.arange(y_min, y_max, 0.01))\n",
    "    \n",
    "    Z = svm_model_poly.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap='viridis')\n",
    "    plt.scatter(X_selected[:, 0], X_selected[:, 1], c=y_train, edgecolor='k', cmap='viridis')\n",
    "    plt.title(f\"SVM Decision Boundary with Polynomial Kernel (Degree {degree})\")\n",
    "    plt.xlabel('Feature 1 (standardized)')\n",
    "    plt.ylabel('Feature 2 (standardized)')\n",
    "    plt.show()\n",
    "\n",
    "# Display the results summary\n",
    "print(\"\\n--- Summary of Polynomial Kernel Results ---\")\n",
    "for degree, metrics in results.items():\n",
    "    print(f\"\\nDegree {degree}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric.capitalize()}: {value:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARAMETER TUNING FOR POLYNOMIAL KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T17:18:55.554567Z",
     "iopub.status.busy": "2024-11-05T17:18:55.554117Z",
     "iopub.status.idle": "2024-11-05T17:18:57.574743Z",
     "shell.execute_reply": "2024-11-05T17:18:57.573396Z",
     "shell.execute_reply.started": "2024-11-05T17:18:55.554522Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Use only a sample subset for interpretation to speed up SHAP\n",
    "X_train_sample, _, y_train_sample, _ = train_test_split(X_train_scaled, y_train, train_size=500, random_state=42, stratify=y_train)\n",
    "\n",
    "# Define parameter grid for polynomial kernel tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'degree': [2, 3, 4],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Train the SVM model with the best parameters found for the polynomial kernel\n",
    "grid_search_poly = GridSearchCV(SVC(kernel='poly', probability=True), param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "grid_search_poly.fit(X_train_sample, y_train_sample)\n",
    "best_poly_model = grid_search_poly.best_estimator_\n",
    "\n",
    "# Fit the best polynomial model to the entire training set for SHAP analysis\n",
    "best_poly_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set (ensure you have a scaled test set)\n",
    "y_pred_poly = best_poly_model.predict(X_test_scaled)  # Ensure you have defined X_test_scaled\n",
    "y_proba_poly = best_poly_model.predict_proba(X_test_scaled)[:, 1]  # Probability estimates for AUC\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy_poly = accuracy_score(y_test, y_pred_poly)  # Ensure you have defined y_test\n",
    "precision_poly = precision_score(y_test, y_pred_poly, average='weighted')\n",
    "recall_poly = recall_score(y_test, y_pred_poly, average='weighted')\n",
    "f1_poly = f1_score(y_test, y_pred_poly, average='weighted')\n",
    "auc_poly = roc_auc_score(y_test, y_proba_poly)  # AUC for binary classification\n",
    "\n",
    "# Display the best model parameters and best cross-validation score\n",
    "print(\"Best Polynomial SVM Model Parameters:\")\n",
    "for param, value in best_poly_model.get_params().items():\n",
    "    print(f\"{param}: {value}\")\n",
    "\n",
    "# Display the best cross-validation score\n",
    "best_cv_score = grid_search_poly.best_score_\n",
    "print(f\"\\nBest Cross-Validation Score (F1 Weighted): {best_cv_score:.4f}\")\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(\"\\nEvaluation Metrics for Polynomial SVM:\")\n",
    "print(f\"Accuracy: {accuracy_poly:.4f}\")\n",
    "print(f\"Precision: {precision_poly:.4f}\")\n",
    "print(f\"Recall: {recall_poly:.4f}\")\n",
    "print(f\"F1 Score: {f1_poly:.4f}\")\n",
    "print(f\"AUC: {auc_poly:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM WITH RBF KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T17:18:57.577479Z",
     "iopub.status.busy": "2024-11-05T17:18:57.576955Z",
     "iopub.status.idle": "2024-11-05T17:19:26.324888Z",
     "shell.execute_reply": "2024-11-05T17:19:26.323515Z",
     "shell.execute_reply.started": "2024-11-05T17:18:57.577407Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define and train the SVM model with an RBF kernel and default gamma='scale'\n",
    "svm_model_rbf = SVC(kernel='rbf', probability=True)  # Using default gamma='scale'\n",
    "svm_model_rbf.fit(X_selected, y_train)  # Assuming X_selected contains only 2 features\n",
    "\n",
    "# Predict on the test set (using the same 2 features as X_selected)\n",
    "y_pred = svm_model_rbf.predict(X_test_scaled[:, :2])  # Use the first two features for testing\n",
    "y_pred_prob = svm_model_rbf.decision_function(X_test_scaled[:, :2])\n",
    "\n",
    "# Calculate classification metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate AUC score, handling binary and multiclass cases\n",
    "if len(set(y)) == 2:\n",
    "    auc = roc_auc_score(y_test, y_pred_prob)\n",
    "else:\n",
    "    y_test_binarized = label_binarize(y_test, classes=np.unique(y))\n",
    "    auc = roc_auc_score(y_test_binarized, y_pred_prob, average=\"weighted\", multi_class=\"ovr\")\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"AUC Score: {auc:.2f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Plot the decision boundary for visualization\n",
    "x_min, x_max = X_selected[:, 0].min() - 1, X_selected[:, 0].max() + 1\n",
    "y_min, y_max = X_selected[:, 1].min() - 1, X_selected[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                     np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "Z = svm_model_rbf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap='viridis')\n",
    "plt.scatter(X_selected[:, 0], X_selected[:, 1], c=y_train, edgecolor='k', cmap='viridis')\n",
    "plt.title(f\"SVM Decision Boundary with RBF Kernel (Gamma = 'scale')\")\n",
    "plt.xlabel('Feature 1 (standardized)')\n",
    "plt.ylabel('Feature 2 (standardized)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARAMETER TUNING FOR RBF KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T17:19:26.327371Z",
     "iopub.status.busy": "2024-11-05T17:19:26.326934Z",
     "iopub.status.idle": "2024-11-05T17:19:27.364050Z",
     "shell.execute_reply": "2024-11-05T17:19:27.362783Z",
     "shell.execute_reply.started": "2024-11-05T17:19:26.327329Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Use only a sample subset for interpretation to speed up SHAP\n",
    "X_train_sample, _, y_train_sample, _ = train_test_split(X_train_scaled, y_train, train_size=500, random_state=42, stratify=y_train)\n",
    "\n",
    "# Define parameter grid for RBF kernel tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Train the SVM model with the best parameters found for the RBF kernel\n",
    "grid_search_rbf = GridSearchCV(SVC(kernel='rbf', probability=True), param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "grid_search_rbf.fit(X_train_sample, y_train_sample)\n",
    "best_rbf_model = grid_search_rbf.best_estimator_\n",
    "\n",
    "# Fit the best RBF model to the entire training set for SHAP analysis\n",
    "best_rbf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set (ensure you have a scaled test set)\n",
    "y_pred_rbf = best_rbf_model.predict(X_test_scaled) \n",
    "y_proba_rbf = best_rbf_model.predict_proba(X_test_scaled)[:, 1]  # Probability estimates for AUC\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy_rbf = accuracy_score(y_test, y_pred_rbf)  # Ensure you have defined y_test\n",
    "precision_rbf = precision_score(y_test, y_pred_rbf, average='weighted')\n",
    "recall_rbf = recall_score(y_test, y_pred_rbf, average='weighted')\n",
    "f1_rbf = f1_score(y_test, y_pred_rbf, average='weighted')\n",
    "auc_rbf = roc_auc_score(y_test, y_proba_rbf)  # AUC for binary classification\n",
    "\n",
    "# Display the best model parameters and best cross-validation score\n",
    "print(\"Best RBF SVM Model Parameters:\")\n",
    "for param, value in best_rbf_model.get_params().items():\n",
    "    print(f\"{param}: {value}\")\n",
    "\n",
    "# Display the best cross-validation score\n",
    "best_cv_score = grid_search_rbf.best_score_\n",
    "print(f\"\\nBest Cross-Validation Score (F1 Weighted): {best_cv_score:.4f}\")\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(\"\\nEvaluation Metrics for RBF SVM:\")\n",
    "print(f\"Accuracy: {accuracy_rbf:.4f}\")\n",
    "print(f\"Precision: {precision_rbf:.4f}\")\n",
    "print(f\"Recall: {recall_rbf:.4f}\")\n",
    "print(f\"F1 Score: {f1_rbf:.4f}\")\n",
    "print(f\"AUC: {auc_rbf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM IMPLEMENTATION FOR SIGMOID KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T17:19:27.366314Z",
     "iopub.status.busy": "2024-11-05T17:19:27.365792Z",
     "iopub.status.idle": "2024-11-05T17:19:27.586262Z",
     "shell.execute_reply": "2024-11-05T17:19:27.584678Z",
     "shell.execute_reply.started": "2024-11-05T17:19:27.366259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Define the Sigmoid kernel function\n",
    "def sigmoid_kernel(X1, X2, alpha=1, beta=0):\n",
    "    # Compute the Sigmoid kernel\n",
    "    return np.tanh(alpha * np.dot(X1, X2.T) + beta)\n",
    "\n",
    "# Create the SVM model using the custom Sigmoid kernel\n",
    "svm_model_sigmoid = SVC(kernel=lambda X1, X2: sigmoid_kernel(X1, X2, alpha=1, beta=0), probability=True)\n",
    "\n",
    "# Fit the model\n",
    "svm_model_sigmoid.fit(X_train_scaled[:, :2], y_train)  # Assuming X_train_scaled contains only 2 features\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = svm_model_sigmoid.predict(X_test_scaled[:, :2])\n",
    "y_pred_prob = svm_model_sigmoid.decision_function(X_test_scaled[:, :2])\n",
    "\n",
    "# Calculate classification metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate AUC score, handling binary and multiclass cases\n",
    "if len(set(y)) == 2:\n",
    "    auc = roc_auc_score(y_test, y_pred_prob)\n",
    "else:\n",
    "    y_test_binarized = label_binarize(y_test, classes=np.unique(y))\n",
    "    auc = roc_auc_score(y_test_binarized, y_pred_prob, average=\"weighted\", multi_class=\"ovr\")\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"AUC Score: {auc:.2f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SENSITIVITY ANALYSIS FOR ALL KERNELS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T17:19:27.594576Z",
     "iopub.status.busy": "2024-11-05T17:19:27.593407Z",
     "iopub.status.idle": "2024-11-05T17:19:59.323968Z",
     "shell.execute_reply": "2024-11-05T17:19:59.322629Z",
     "shell.execute_reply.started": "2024-11-05T17:19:27.594494Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def sensitivity_analysis_all_kernels(X, y, param_grid):\n",
    "    results = []\n",
    "    \n",
    "    for kernel in param_grid['kernel']:\n",
    "        for C in param_grid['C']:\n",
    "            if kernel == 'linear':\n",
    "                model = SVC(kernel=kernel, C=C)\n",
    "                score = cross_val_score(model, X, y, cv=5, scoring='accuracy').mean()\n",
    "                results.append((kernel, C, None, None, score))\n",
    "                \n",
    "            elif kernel == 'rbf':\n",
    "                for gamma in param_grid['gamma']:\n",
    "                    model = SVC(kernel=kernel, C=C, gamma=gamma)\n",
    "                    score = cross_val_score(model, X, y, cv=5, scoring='accuracy').mean()\n",
    "                    results.append((kernel, C, gamma, None, score))\n",
    "                    \n",
    "            elif kernel == 'poly':\n",
    "                for degree in param_grid['degree']:\n",
    "                    model = SVC(kernel=kernel, C=C, degree=degree)\n",
    "                    score = cross_val_score(model, X, y, cv=5, scoring='accuracy').mean()\n",
    "                    results.append((kernel, C, None, degree, score))\n",
    "                    \n",
    "            elif kernel == 'sigmoid':\n",
    "                for gamma in param_grid['gamma']:\n",
    "                    model = SVC(kernel=kernel, C=C, gamma=gamma)\n",
    "                    score = cross_val_score(model, X, y, cv=5, scoring='accuracy').mean()\n",
    "                    results.append((kernel, C, gamma, None, score))\n",
    "    \n",
    "    return pd.DataFrame(results, columns=['Kernel', 'C', 'Gamma', 'Degree', 'Accuracy'])\n",
    "\n",
    "# Define the parameter grid for the analysis\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    'C': np.logspace(-2, 2, 5),  # C from 0.01 to 100\n",
    "    'gamma': [0.001, 0.01, 0.1, 1],  # Different values of gamma\n",
    "    'degree': [2, 3, 4]  # Degrees for polynomial\n",
    "}\n",
    "\n",
    "# Run the sensitivity analysis\n",
    "sensitivity_results = sensitivity_analysis_all_kernels(X, y, param_grid)\n",
    "print(sensitivity_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOTTING HEATMAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T17:19:59.325815Z",
     "iopub.status.busy": "2024-11-05T17:19:59.325390Z",
     "iopub.status.idle": "2024-11-05T17:20:00.763119Z",
     "shell.execute_reply": "2024-11-05T17:20:00.761590Z",
     "shell.execute_reply.started": "2024-11-05T17:19:59.325743Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_heatmaps(sensitivity_results):\n",
    "    kernels = sensitivity_results['Kernel'].unique()\n",
    "    \n",
    "    for kernel in kernels:\n",
    "        kernel_data = sensitivity_results[sensitivity_results['Kernel'] == kernel]\n",
    "        \n",
    "        if kernel == 'linear':\n",
    "            heatmap_data = kernel_data.pivot_table(index='C', values='Accuracy')\n",
    "            plt.figure(figsize=(6, 5))\n",
    "            sns.heatmap(heatmap_data, annot=True, cmap='viridis', cbar_kws={'label': 'Accuracy Score'})\n",
    "            plt.title(f'Sensitivity Analysis Heatmap (SVM with {kernel.capitalize()} Kernel)')\n",
    "            plt.xlabel('C')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.show()\n",
    "        \n",
    "        elif kernel == 'rbf':\n",
    "            heatmap_data = kernel_data.pivot_table(index='C', columns='Gamma', values='Accuracy')\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(heatmap_data, annot=True, cmap='viridis', fmt=\".2f\", cbar_kws={'label': 'Accuracy Score'})\n",
    "            plt.title(f'Sensitivity Analysis Heatmap (SVM with {kernel.capitalize()} Kernel)')\n",
    "            plt.xlabel('Gamma')\n",
    "            plt.ylabel('C')\n",
    "            plt.show()\n",
    "        \n",
    "        elif kernel == 'poly':\n",
    "            heatmap_data = kernel_data.pivot_table(index='C', columns='Degree', values='Accuracy')\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(heatmap_data, annot=True, cmap='viridis', fmt=\".2f\", cbar_kws={'label': 'Accuracy Score'})\n",
    "            plt.title(f'Sensitivity Analysis Heatmap (SVM with {kernel.capitalize()} Kernel)')\n",
    "            plt.xlabel('Degree')\n",
    "            plt.ylabel('C')\n",
    "            plt.show()\n",
    "        \n",
    "        elif kernel == 'sigmoid':\n",
    "            heatmap_data = kernel_data.pivot_table(index='C', columns='Gamma', values='Accuracy')\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(heatmap_data, annot=True, cmap='viridis', fmt=\".2f\", cbar_kws={'label': 'Accuracy Score'})\n",
    "            plt.title(f'Sensitivity Analysis Heatmap (SVM with {kernel.capitalize()} Kernel)')\n",
    "            plt.xlabel('Gamma')\n",
    "            plt.ylabel('C')\n",
    "            plt.show()\n",
    "\n",
    "# Plot the heatmaps for the results\n",
    "plot_heatmaps(sensitivity_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T17:20:00.765749Z",
     "iopub.status.busy": "2024-11-05T17:20:00.765044Z",
     "iopub.status.idle": "2024-11-05T17:20:01.059765Z",
     "shell.execute_reply": "2024-11-05T17:20:01.057629Z",
     "shell.execute_reply.started": "2024-11-05T17:20:00.765689Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_degree_sensitivity(sensitivity_results, specific_C):\n",
    "    degree_results = sensitivity_results[(sensitivity_results['C'] == specific_C) & \n",
    "                                         (sensitivity_results['Kernel'] == 'poly')]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=degree_results, x='Degree', y='Accuracy', marker='o')  # Changed 'ROC AUC' to 'Accuracy'\n",
    "    plt.title(f'SVM Performance Sensitivity to Kernel Degree (C={specific_C})')\n",
    "    plt.xlabel('Degree of Polynomial Kernel')\n",
    "    plt.ylabel('Accuracy Score')  # Changed label to 'Accuracy Score'\n",
    "    plt.xticks(degree_results['Degree'])\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage for degree sensitivity visualization\n",
    "plot_degree_sensitivity(sensitivity_results, specific_C=10)  # Adjust C as needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP FOR FEATURE CONTRIBUTIONS IN THE OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T17:20:01.062287Z",
     "iopub.status.busy": "2024-11-05T17:20:01.061752Z",
     "iopub.status.idle": "2024-11-05T17:38:55.941259Z",
     "shell.execute_reply": "2024-11-05T17:38:55.937663Z",
     "shell.execute_reply.started": "2024-11-05T17:20:01.062241Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shap\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assume X_train and X_test are your training and test features and y_train and y_test are the labels\n",
    "\n",
    "# Scale your features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the Sigmoid kernel function\n",
    "def sigmoid_kernel(X1, X2, alpha=1, beta=0):\n",
    "    return np.tanh(alpha * np.dot(X1, X2.T) + beta)\n",
    "\n",
    "# Create and fit the SVM model\n",
    "svm_model_sigmoid = SVC(kernel=lambda X1, X2: sigmoid_kernel(X1, X2, alpha=1, beta=0), probability=True)\n",
    "svm_model_sigmoid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = svm_model_sigmoid.predict(X_test_scaled)\n",
    "\n",
    "# Print accuracy and classification report\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Step 3: Use SHAP to explain predictions\n",
    "# Randomly sample a subset of the test set for SHAP\n",
    "sample_size = 100  # Set the sample size\n",
    "sample_indices = np.random.choice(X_test_scaled.shape[0], size=sample_size, replace=False)\n",
    "X_sample = X_test_scaled[sample_indices]\n",
    "\n",
    "explainer = shap.KernelExplainer(svm_model_sigmoid.predict_proba, X_train_scaled)\n",
    "shap_values = explainer.shap_values(X_sample)\n",
    "\n",
    "# Step 4: Plot SHAP summary for the sampled data\n",
    "shap.summary_plot(shap_values, X_sample, feature_names=[f'Feature {i}' for i in range(X_sample.shape[1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1560515,
     "sourceId": 2570474,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
